"""
Erweiterte Logging-System für EHS-Sentinel
Detaillierte Protokollierung von Sensor-Kommunikation mit Filteroptionen
"""

import logging
import json
import os
import gzip
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum
import asyncio

from CustomLogger import logger

class LogLevel(Enum):
    """Log-Level für verschiedene Ereignisse"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

class LogCategory(Enum):
    """Kategorien für Logs"""
    SENSOR_COMMUNICATION = "sensor_communication"
    MQTT_COMMUNICATION = "mqtt_communication"
    DATA_CONVERSION = "data_conversion"
    ERROR_HANDLING = "error_handling"
    SYSTEM_STATUS = "system_status"
    PERFORMANCE = "performance"

@dataclass
class LogEntry:
    """Strukturierter Log-Eintrag"""
    timestamp: datetime
    level: LogLevel
    category: LogCategory
    sensor_name: Optional[str]
    message: str
    details: Dict[str, Any]
    duration_ms: Optional[float] = None
    error_code: Optional[str] = None
    correlation_id: Optional[str] = None

class StructuredLogger:
    """
    Erweiterte Logging-Klasse mit strukturierten Logs und Filteroptionen.
    Speichert detaillierte Informationen über Sensor-Kommunikation.
    """
    
    def __init__(self):
        self.log_entries: List[LogEntry] = []
        self.max_entries = 10000
        self.log_dir = "/data/logs"
        self.current_log_file = None
        
        # Erstelle Log-Verzeichnis
        os.makedirs(self.log_dir, exist_ok=True)
        
        # Setup strukturierte Logging-Handler
        self._setup_structured_logging()
    
    def _setup_structured_logging(self):
        """Richtet strukturierte Logging-Handler ein"""
        # Erstelle separaten Logger für strukturierte Logs
        self.structured_logger = logging.getLogger('ehs_structured')
        self.structured_logger.setLevel(logging.DEBUG)
        
        # Entferne vorhandene Handler
        for handler in self.structured_logger.handlers[:]:
            self.structured_logger.removeHandler(handler)
        
        # JSON-File-Handler für strukturierte Logs
        log_file = os.path.join(self.log_dir, f"structured_{datetime.now().strftime('%Y%m%d')}.jsonl")
        self.current_log_file = log_file
        
        file_handler = logging.FileHandler(log_file)
        file_handler.setLevel(logging.DEBUG)
        
        # JSON-Formatter
        json_formatter = JsonFormatter()
        file_handler.setFormatter(json_formatter)
        
        self.structured_logger.addHandler(file_handler)
        
        # Verhindere Propagation zum Root-Logger
        self.structured_logger.propagate = False
    
    def log_sensor_communication(self, sensor_name: str, action: str, 
                                details: Dict[str, Any], level: LogLevel = LogLevel.INFO,
                                duration_ms: float = None, error_code: str = None):
        """Protokolliert Sensor-Kommunikation"""
        entry = LogEntry(
            timestamp=datetime.now(),
            level=level,
            category=LogCategory.SENSOR_COMMUNICATION,
            sensor_name=sensor_name,
            message=f"Sensor {action}: {sensor_name}",
            details=details,
            duration_ms=duration_ms,
            error_code=error_code
        )
        
        self._add_log_entry(entry)
    
    def log_mqtt_communication(self, topic: str, action: str, payload: Any,
                              level: LogLevel = LogLevel.INFO, sensor_name: str = None):
        """Protokolliert MQTT-Kommunikation"""
        entry = LogEntry(
            timestamp=datetime.now(),
            level=level,
            category=LogCategory.MQTT_COMMUNICATION,
            sensor_name=sensor_name,
            message=f"MQTT {action}: {topic}",
            details={
                "topic": topic,
                "action": action,
                "payload": payload,
                "payload_size": len(str(payload)) if payload else 0
            }
        )
        
        self._add_log_entry(entry)
    
    def log_data_conversion(self, sensor_name: str, conversion_type: str,
                           original_value: Any, converted_value: Any,
                           success: bool = True, error_message: str = None):
        """Protokolliert Datenkonvertierung"""
        level = LogLevel.INFO if success else LogLevel.ERROR
        
        entry = LogEntry(
            timestamp=datetime.now(),
            level=level,
            category=LogCategory.DATA_CONVERSION,
            sensor_name=sensor_name,
            message=f"Data conversion {conversion_type}: {sensor_name}",
            details={
                "conversion_type": conversion_type,
                "original_value": original_value,
                "converted_value": converted_value,
                "success": success,
                "error_message": error_message
            },
            error_code="CONVERSION_ERROR" if not success else None
        )
        
        self._add_log_entry(entry)
    
    def log_error(self, category: LogCategory, message: str, details: Dict[str, Any],
                  sensor_name: str = None, error_code: str = None):
        """Protokolliert Fehler"""
        entry = LogEntry(
            timestamp=datetime.now(),
            level=LogLevel.ERROR,
            category=category,
            sensor_name=sensor_name,
            message=message,
            details=details,
            error_code=error_code
        )
        
        self._add_log_entry(entry)
    
    def log_performance(self, operation: str, duration_ms: float, 
                       details: Dict[str, Any] = None):
        """Protokolliert Performance-Metriken"""
        entry = LogEntry(
            timestamp=datetime.now(),
            level=LogLevel.INFO,
            category=LogCategory.PERFORMANCE,
            sensor_name=None,
            message=f"Performance: {operation}",
            details=details or {},
            duration_ms=duration_ms
        )
        
        self._add_log_entry(entry)
    
    def _add_log_entry(self, entry: LogEntry):
        """Fügt Log-Eintrag hinzu"""
        # Füge zu In-Memory-Liste hinzu
        self.log_entries.append(entry)
        
        # Begrenze Anzahl der In-Memory-Einträge
        if len(self.log_entries) > self.max_entries:
            self.log_entries = self.log_entries[-self.max_entries:]
        
        # Schreibe in strukturierte Log-Datei
        log_data = asdict(entry)
        log_data['timestamp'] = entry.timestamp.isoformat()
        log_data['level'] = entry.level.value
        log_data['category'] = entry.category.value
        
        self.structured_logger.info(json.dumps(log_data))
    
    def get_logs(self, filters: Dict[str, Any] = None, limit: int = 100) -> List[Dict[str, Any]]:
        """Gibt gefilterte Logs zurück"""
        filtered_entries = self.log_entries
        
        if filters:
            # Filter nach Level
            if 'level' in filters:
                level_filter = LogLevel(filters['level'])
                filtered_entries = [e for e in filtered_entries if e.level == level_filter]
            
            # Filter nach Kategorie
            if 'category' in filters:
                category_filter = LogCategory(filters['category'])
                filtered_entries = [e for e in filtered_entries if e.category == category_filter]
            
            # Filter nach Sensor
            if 'sensor_name' in filters:
                sensor_filter = filters['sensor_name']
                filtered_entries = [e for e in filtered_entries if e.sensor_name == sensor_filter]
            
            # Filter nach Zeitraum
            if 'start_time' in filters:
                start_time = datetime.fromisoformat(filters['start_time'])
                filtered_entries = [e for e in filtered_entries if e.timestamp >= start_time]
            
            if 'end_time' in filters:
                end_time = datetime.fromisoformat(filters['end_time'])
                filtered_entries = [e for e in filtered_entries if e.timestamp <= end_time]
            
            # Filter nach Fehlern
            if 'errors_only' in filters and filters['errors_only']:
                filtered_entries = [e for e in filtered_entries if e.level in [LogLevel.ERROR, LogLevel.CRITICAL]]
        
        # Sortiere nach Zeitstempel (neueste zuerst)
        filtered_entries.sort(key=lambda x: x.timestamp, reverse=True)
        
        # Begrenze Anzahl
        filtered_entries = filtered_entries[:limit]
        
        # Konvertiere zu Dict
        return [
            {
                "timestamp": entry.timestamp.isoformat(),
                "level": entry.level.value,
                "category": entry.category.value,
                "sensor_name": entry.sensor_name,
                "message": entry.message,
                "details": entry.details,
                "duration_ms": entry.duration_ms,
                "error_code": entry.error_code
            }
            for entry in filtered_entries
        ]
    
    def get_log_statistics(self, hours: int = 24) -> Dict[str, Any]:
        """Gibt Log-Statistiken zurück"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        recent_entries = [e for e in self.log_entries if e.timestamp > cutoff_time]
        
        # Statistiken nach Level
        level_stats = {}
        for level in LogLevel:
            level_stats[level.value] = sum(1 for e in recent_entries if e.level == level)
        
        # Statistiken nach Kategorie
        category_stats = {}
        for category in LogCategory:
            category_stats[category.value] = sum(1 for e in recent_entries if e.category == category)
        
        # Sensor-Statistiken
        sensor_stats = {}
        for entry in recent_entries:
            if entry.sensor_name:
                if entry.sensor_name not in sensor_stats:
                    sensor_stats[entry.sensor_name] = {"total": 0, "errors": 0}
                sensor_stats[entry.sensor_name]["total"] += 1
                if entry.level in [LogLevel.ERROR, LogLevel.CRITICAL]:
                    sensor_stats[entry.sensor_name]["errors"] += 1
        
        # Performance-Statistiken
        performance_entries = [e for e in recent_entries if e.duration_ms is not None]
        avg_duration = sum(e.duration_ms for e in performance_entries) / len(performance_entries) if performance_entries else 0
        
        return {
            "time_period_hours": hours,
            "total_entries": len(recent_entries),
            "level_breakdown": level_stats,
            "category_breakdown": category_stats,
            "sensor_breakdown": sensor_stats,
            "performance": {
                "avg_duration_ms": round(avg_duration, 2),
                "total_operations": len(performance_entries)
            },
            "error_rate": round(level_stats.get("ERROR", 0) / len(recent_entries) * 100, 2) if recent_entries else 0
        }
    
    def export_logs(self, filters: Dict[str, Any] = None, format: str = "json") -> str:
        """Exportiert Logs in verschiedenen Formaten"""
        logs = self.get_logs(filters, limit=10000)
        
        if format == "json":
            return json.dumps(logs, indent=2)
        elif format == "csv":
            import csv
            import io
            
            output = io.StringIO()
            if logs:
                fieldnames = logs[0].keys()
                writer = csv.DictWriter(output, fieldnames=fieldnames)
                writer.writeheader()
                for log in logs:
                    # Flatten details for CSV
                    flattened_log = log.copy()
                    if 'details' in flattened_log:
                        details = flattened_log.pop('details')
                        for key, value in details.items():
                            flattened_log[f"details_{key}"] = value
                    writer.writerow(flattened_log)
            
            return output.getvalue()
        else:
            raise ValueError(f"Unsupported format: {format}")

class JsonFormatter(logging.Formatter):
    """JSON-Formatter für strukturierte Logs"""
    
    def format(self, record):
        # Bereits JSON-formatierte Nachrichten direkt zurückgeben
        return record.getMessage()

# Globale Instanz
structured_logger = StructuredLogger()